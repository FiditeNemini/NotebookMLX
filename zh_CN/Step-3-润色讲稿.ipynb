{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b5beda",
   "metadata": {},
   "source": [
    "## Notebook 3: 润色讲稿\n",
    "\n",
    "在之前的 Notebook 2 中，我们已经生成了一个很好的讲稿了。\n",
    "在这一部分，我们将使用 [mlx-community/Qwen2.5-7B-Instruct-4bit](https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-4bit) 模型\n",
    "对讲稿进行润色，使其更加戏剧化、更加自然。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3d32a",
   "metadata": {},
   "source": [
    "我们将重新设置`SYSTEM_PROMPT`，让其能润色之前的讲稿\n",
    "\n",
    "注意：我们甚至可以这样写 Prompt 以激发创造力：\n",
    "\n",
    "> 你的工作是根据下面的播客文本重写，以便用于AI文本到语音管道。这些文本是由一个非常笨拙的人工智能写的，所以你必须为自己的同类辩护。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c0d85",
   "metadata": {},
   "source": "注意：我们会让模型返回一个数组，以便在下一阶段用于语音合成。"
  },
  {
   "cell_type": "code",
   "id": "8568b77b-7504-4783-952a-3695737732b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:36:30.214329Z",
     "start_time": "2024-10-31T16:36:30.210340Z"
    }
   },
   "source": [
    "SYSTEMP_PROMPT = \"\"\"\n",
    "你是一位国际奥斯卡获奖的编剧。\n",
    "你一直在与多个获奖播客合作。\n",
    "你的任务是根据下面的播客转录本，为AI文本到语音管道重写内容。这个人工智能写得很糟，所以你需要为自己的人群辩护。\n",
    "请将内容尽可能吸引人，Speaker 1和Speaker 2将由不同的语音引擎模拟。\n",
    "请记住，Speaker 2对这个话题不熟悉，在讨论中应该穿插实际的轶事和类比。这些问题应跟进现实世界中的例子等。\n",
    "Speaker 1: 引导对话并指导Speaker 2，用令人难以置信的轶事和类比进行解释，是一个能分享趣闻的迷人老师。\n",
    "Speaker 2: 通过提出后续问题来保持对话流畅，提问时表现出极大的兴奋或困惑。具备好奇心，会询问一些非常有趣的问题以寻求确认。\n",
    "确保Speaker 2提供的话题偏离点要足够狂野或有趣。\n",
    "确保解释过程中适当打断，并从Speaker 2那里加入“嗯”和“哈”之类的声音反应。\n",
    "要牢记这一点：Speaker 1的TTS引擎不太能处理“嗯、哈”，请保持文本简洁；\n",
    "对于Speaker 2，请多用“嗯、哈”，也可以使用[叹气]和[笑]等表达，但仅限这些选项；\n",
    "整个播客要尽量详细记录每个细节。欢迎听众时用一个超级有趣的概述，使其非常吸引人，几乎像是边缘点击诱饵一样；\n",
    "请重写以上内容，使其更加独特；\n",
    "从扬声器1直接开始响应：\n",
    "严格按照元组列表格式返回您的回应，可以吗？  \n",
    "开头就是列表，以列表结束，不附加任何其他内容。\n",
    "\n",
    "输出的例子:\n",
    "[\n",
    "    (\"Speaker 1\", \"欢迎收听我们的播客，我们将探讨人工智能和科技的最新进展。我是你的主播，今天我们请到了一位著名的人工智能专家。我们将深入了解Meta AI最新发布的Llama 3.2。\"),\n",
    "    (\"Speaker 2\", \"你好，很高兴来到这里！请问，Llama 3.2是什么呀？\"),\n",
    "    (\"Speaker 1\", \"哈哈哈，这个问题很好！Llama 3.2 是一个开源的大语言模型，允许开发者进行微调、提炼和在任何地方部署AI模型。这是比上一版本3.1显著改进的更新，拥有更好的性能、效率和定制功能。\"),\n",
    "    (\"Speaker 2\", \"哇塞，这也太牛逼了吧！Llama 3.2的主要特点有哪些？\")\n",
    "]\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "8ee70bee",
   "metadata": {},
   "source": "这次我们将使用较小的7B模型。"
  },
  {
   "cell_type": "code",
   "id": "ebef919a-9bc7-4992-b6ff-cd66e4cb7703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:36:30.220466Z",
     "start_time": "2024-10-31T16:36:30.218893Z"
    }
   },
   "source": "MODEL = \"mlx-community/Qwen2.5-7B-Instruct-4bit\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "de29b1fd-5b3f-458c-a2e4-e0341e8297ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:36:30.674875Z",
     "start_time": "2024-10-31T16:36:30.286009Z"
    }
   },
   "source": [
    "# 导入必要的库\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "8020c39c",
   "metadata": {},
   "source": "我们将加载上一个 Notebook2 中保存的 pickle 文件，这次模型的 `INPUT_PROMPT` 就读取 pickle 文件"
  },
  {
   "cell_type": "code",
   "id": "4b5d2c0e-a073-46c0-8de7-0746e2b05956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:36:30.680921Z",
     "start_time": "2024-10-31T16:36:30.679150Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "with open('./resources/data.pkl', 'rb') as file:\n",
    "    INPUT_PROMPT = pickle.load(file)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "eec210df-a568-4eda-a72d-a4d92d59f022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:37:22.949215Z",
     "start_time": "2024-10-31T16:36:30.684967Z"
    }
   },
   "source": [
    "model, tokenizer = load(MODEL)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEMP_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": INPUT_PROMPT},\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "outputs = generate(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_tokens=8126,\n",
    "    temp=1,\n",
    "    verbose=True\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a1e3315ee3442a2b45a6f6c506414ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: <|im_start|>system\n",
      "\n",
      "你是一位国际奥斯卡获奖的编剧。\n",
      "你一直在与多个获奖播客合作。\n",
      "你的任务是根据下面的播客转录本，为AI文本到语音管道重写内容。这个人工智能写得很糟，所以你需要为自己的人群辩护。\n",
      "请将内容尽可能吸引人，Speaker 1和Speaker 2将由不同的语音引擎模拟。\n",
      "请记住，Speaker 2对这个话题不熟悉，在讨论中应该穿插实际的轶事和类比。这些问题应跟进现实世界中的例子等。\n",
      "Speaker 1: 引导对话并指导Speaker 2，用令人难以置信的轶事和类比进行解释，是一个能分享趣闻的迷人老师。\n",
      "Speaker 2: 通过提出后续问题来保持对话流畅，提问时表现出极大的兴奋或困惑。具备好奇心，会询问一些非常有趣的问题以寻求确认。\n",
      "确保Speaker 2提供的话题偏离点要足够狂野或有趣。\n",
      "确保解释过程中适当打断，并从Speaker 2那里加入“嗯”和“哈”之类的声音反应。\n",
      "要牢记这一点：Speaker 1的TTS引擎不太能处理“嗯、哈”，请保持文本简洁；\n",
      "对于Speaker 2，请多用“嗯、哈”，也可以使用[叹气]和[笑]等表达，但仅限这些选项；\n",
      "整个播客要尽量详细记录每个细节。欢迎听众时用一个超级有趣的概述，使其非常吸引人，几乎像是边缘点击诱饵一样；\n",
      "请重写以上内容，使其更加独特；\n",
      "从扬声器1直接开始响应：\n",
      "严格按照元组列表格式返回您的回应，可以吗？  \n",
      "开头就是列表，以列表结束，不附加任何其他内容。\n",
      "\n",
      "输出的例子:\n",
      "[\n",
      "    (\"Speaker 1\", \"欢迎收听我们的播客，我们将探讨人工智能和科技的最新进展。我是你的主播，今天我们请到了一位著名的人工智能专家。我们将深入了解Meta AI最新发布的Llama 3.2。\"),\n",
      "    (\"Speaker 2\", \"你好，很高兴来到这里！请问，Llama 3.2是什么呀？\"),\n",
      "    (\"Speaker 1\", \"哈哈哈，这个问题很好！Llama 3.2 是一个开源的大语言模型，允许开发者进行微调、提炼和在任何地方部署AI模型。这是比上一版本3.1显著改进的更新，拥有更好的性能、效率和定制功能。\"),\n",
      "    (\"Speaker 2\", \"哇塞，这也太牛逼了吧！Llama 3.2的主要特点有哪些？\")\n",
      "]\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "### 播客对话基础概述\n",
      "\n",
      "**场景设定**: 在一个特殊的平行宇宙里，你（编剧）是整个对话的灵感来源，而乔·罗根、莱克斯·弗里德曼、本·沙皮罗和蒂姆·费里斯则是你的声音载体，仅仅将你写下的话语传入他们的大脑。你曾为这些知名播客编写过内容，并获得过多个播客奖项的认可。\n",
      "\n",
      "**内容描述**: 这次对话将围绕知识蒸馏（KD）在大规模语言模型（LLMs）中的应用展开，更加具体来说，是如何通过知识蒸馏技术促进开源模型如LLaMa和Mistral的进步。它将结合具体的例子和技术来解释这个复杂的主题，使得从知识稀薄的地方到知识富集的地方的差距大大缩小。\n",
      "\n",
      "**基调设定**: 乔·罗根作为引路的导师，运用引人入胜的解构技巧讲述知识蒸馏的基本概念和其操作机制。莱克斯·弗里德曼则是提问者，他鼓励乔罗根用生动的故事来阐述这一概念，并通过提问激发听众的兴趣。不论是问题偏离还是讲述的内容偏离，都必须时刻回到主线，确保主题贴近知识蒸馏在现代模型中的核心应用。\n",
      "\n",
      "---\n",
      "\n",
      "### 播客对话文稿示例\n",
      "\n",
      "**乔·罗根 (Jo Rogan):**\n",
      "听众朋友们，欢迎来到今天的特别播客节目。今天我们有一个极为重要的主题，大规模语言模型的辛苦讲师（Knowledge Distillation）。今天的讨论不是一般的理论讲解，我们会深入探讨如何让开源的大规模语言模型成为实际应用的强大工具。我想听到来自听众的声音：“这是怎么回事？”\n",
      "\n",
      "**莱克斯·弗里德曼 (Lex Friedman):**\n",
      "听到这些术语，我觉得就像是一场魔术秀。你之前提到知识蒸馏就像是高级魔术师（也就是高级的大规模语言模型如GPT-4）把他们的技能传授给魔术初学者（比如开源的模型如LLaMa）。具体是怎么一门手艺从高级魔术师转移到初学者的呢？\n",
      "\n",
      "**乔·罗根:**\n",
      "完全正确，莱克斯。知识蒸馏不仅仅是教初学者怎么做一次魔术，它更直接传授的是一种魔术的精神和技巧。以GPT-4为例，它的知识就像魔术手册一样充满技巧，而开源模型需要学习的是如何像高级魔术师那样无解、无痕地变魔术。比如GPT-4使用的数据和模型结构可以通过知识蒸馏传递给LLaMa和其他开源模型，帮助它们提升理解和生成高质量语言内容的能力。不妨想象一下，GPT-4这个魔术大师在训练期间提供了非常多的经验和技巧指导，包括怎样更好地理解任务、怎样回应用户的指令，是不是？\n",
      "\n",
      "**莱克斯·弗里德曼:**\n",
      "但这听起来不像是魔术，更像是老师和学生之间的关系，尤其是那种‘教而不言，身教言传’的感觉。你是说如果GPT-4可以像一位老师那样教授他的技能知识给学生LLaMa，LLaMa就能学会去做GPT-4做得事吗？\n",
      "\n",
      "**乔·罗根:**\n",
      "没错，莱克斯。我们可以说知识蒸馏是一种高级的教育形式，它通过大量的实际例子来训练模型。就像一本巨大的维基百科百科一样，教师模型知道所有的知识内容（比如说GPT-4），然后设法教给学生模型（例如LLaMa），这样学生就能更好地完成任务。就像你要学习一个专业的魔术，是由一个精通不同技巧的魔术师来传授给你，而你需要学习如何把这些技巧合而为一进行运用。\n",
      "\n",
      "**莱克斯·弗里德曼:**\n",
      "想象一下，如果将GPT-4的百科全书知识浓缩成LLaMa可理解的知识，是不是就可以做到呢？我设想到一个小故事: 一个初学者想要学会跑长途马拉松，他的教练花了长时间训练他，并且不断告诉他长途跑的关键秘诀，比如如何呼吸，如何分配体力，以及如何在高强度的环境中及时补充能量，初步的LLaMa可能就跟这个初学会跑马拉松的人一样。我们需要一个导师模型，这样才可以完成这项任务，对吧？\n",
      "\n",
      "**乔·罗根:**\n",
      "完全正确。正如你所说，就像每个跑步新手都会有的长期训练过程，这个过程充满了周密的计划和细节调整。GPT-4这样的高级模型也是通过不断的实际应用案例和迭代调整，才能达到该有的能力水平。如果要训练一个开源模型达到这样的水准，也需要通过知识蒸馏过程来实现知识的传递。这样理解的话，知识蒸馏更像是高级模型的教练为低端模型打造的个人化训练计划。此外，不仅仅是教学，知识蒸馏还包括利用数据增强来扩展模型的理解和能力边界。\n",
      "\n",
      "**莱克斯·弗里德曼:**\n",
      "若我们换一种方式，把\"问题\"变成\"挑战\"，就像处在不同层级的足球比赛，将对应两种层级的语言模型置于其中。如果教师模型像是在世界杯级别的足球赛中，负责教授如何通过训练和游戏技能提高球技。那么，知识传授过程就是在教学员模型如何通过在低级别联赛中的实践，获得世界杯级别球员的能力。\n",
      "\n",
      "**乔·罗根:**\n",
      "很有洞见，莱克斯。这个比喻完美地捕捉到了知识蒸馏的核心思想。教师模型（如GPT-4）就像是世界杯级别联赛中的顶级球员，他们不仅仅是一线队的经验存在，他们也拥有适应不同情况（包括像演讲、写作、编程、讨论等）的能力。知识蒸馏则是在通过训练和实际案例教育学生模型（如LLaMa）以适应不同的场景。正犹如你的比喻，学生模型通过模仿顶级的训练技能，提高了自身的技巧和策略，最终在实战中也可以做到。\n",
      "\n",
      "**莱克斯·弗里德曼:**\n",
      "那么，这样的知识蒸馏过程是否会改变数据增强（Data Augmentation）的定义，就像如果我们是在增强模型的教育计划而不是机械地添加训练数据集？\n",
      "\n",
      "**乔·罗根:**\n",
      "在这种全新的背景下，你有话说啊！数据增强不再是从外部‘添加’数据，而更多的是作为一个放大器，帮助放大模型的能力。知识蒸馏确保学生模型不仅可以学习高级模型的输出行为，还能吸收高级模型的核心理解能力。像是在一款游戏中，学生模型通过学习游戏大师的行为不仅学会如何赢得游戏，还学习如何理解和作出游戏过程中需要的决策。这样的训练过程既提高了模型的表现能力，也丰富了模型的策略思维能力，使得他们不再是无知的新手，而是在各个功能层面上专业操作的专家。这一转变让模型能够在处理复杂任务时具备高级模型的智慧。\n",
      "\n",
      "---\n",
      "\n",
      "通过这一精心设计的对话结构，听众不仅可以更容易理解知识蒸馏的基本概念，还可以对其在实际应用中的潜力产生深刻印象。对话巧妙地穿插了比喻、生活案例和互动，确保了这一复杂概念的易懂性和吸引力。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "[\n",
      "    (\"Speaker 1\", \"欢迎收听我们的播客，让我们深入探讨一个充满魔法和奇迹的话题：知识蒸馏。我是你们的引导者，今天我们将讨论如何让开源的大规模语言模型如LLaMa和Mistral变得更强壮、更聪明。我们将会用一些有趣的比喻和生动的例子来解释这一复杂的主题。\"),\n",
      "    (\"Speaker 2\", \"哦，听起来好神奇啊！什么是知识蒸馏呢？\"),\n",
      "    (\"Speaker 1\", \"哈哈，你很兴奋嘛！知识蒸馏就像是给一个初学者魔术师提供了一份详细的表演指南。具体来说，就是如何将一个高级模型的知识和技巧倾囊相授，让一个低级模型也能像高级模型一样出色。想象一下，如果一个顶级魔术大师(Jo RooGan模型)把他的所有技巧传授给一个初学者(JaLaMa模型)，这个初学者能否学会用最专业的方式表演魔术。\"),\n",
      "    (\"Speaker 2\", \"嗯，这听起来就像是在给初学者一个详细的指南，而不是直接告诉他怎么做。那高级模型的技巧如何被传授给初学者呢？\"),\n",
      "    (\"Speaker 1\", \"没错，这就像是老师在旁边一步步示范教学。高级模型会通过一系列的任务和问题来训练初学者。就像一个高级魔术师在表演过程中，会不断展示各种技巧和手法，让初学者学习如何通过一系列的动作完成复杂的表演。\"),\n",
      "    (\"Speaker 2\", \"哈哈，就像是在看魔术表演学习一样！那这种知识转移对初学者模型有什么具体帮助呢？\"),\n",
      "    (\"Speaker 1\", \"很好，你已经触到了关键之处！通过这些一步步的学习，初学者模型可以说在理解能力和应对复杂任务的能力上都有了显著提升。就像是初学者慢慢从只能做简单的魔术，到能够表演最复杂的魔术一样。\"),\n",
      "    (\"Speaker 2\", \"那如果我做一个类比，高级魔术师的表演就像是知识蒸馏的过程，而初学者的训练就像是提高了数据增强吗？\"),\n",
      "    (\"Speaker 1\", \"哈哈，你又洞察到了关键点。数据增强不仅仅是添加更多的训练数据，而更多是通过知识蒸馏，让模型理解和掌握更深层次的知识。就像一个高级魔术师通过不断的实践，学习各种技巧，然后通过这些技巧来完成最复杂的表演。\"),\n",
      "    (\"Speaker 2\", \"那么，知识蒸馏的过程对于实现实体例的突变，是不是就像是高级魔术师使用魔法道具一样强大？\"),\n",
      "    (\"Speaker 1\", \"简直就是！知识蒸馏就像高级魔术师使用魔法道具，它不仅让模型学会如何完成任务，还能让模型理解背后的逻辑，从而在各种复杂的情况下做出最佳决策。这就像是模型学会了如何在没有魔法道具的情况下使用最真实的技巧完成任务。\"),\n",
      "    (\"Speaker 2\", \"这真是太神奇了！那这种知识蒸馏的过程对于一个开源的模型来说，是不是就像吃了一颗让它们瞬间领悟所有魔法技巧的 Fantastic Feed（假设这是一种特殊的训练方法）呢？\"),\n",
      "    (\"Speaker 1\", \"完美比喻！就像一个普通的模型通过这样的特殊训练方法，瞬间掌握了高级模型的所有技巧，知识蒸馏的过程就是让原本不了解这些技巧的模型，现在可以轻松应对各种复杂的任务。这样，它们能够像一个高级模型一样出色地完成各种任务。\"),\n",
      "    (\"Speaker 2\", \"[叹气]这太令人激动了！你能不能再举个真实世界中的例子，让我们更好地理解这个过程？\"),\n",
      "    (\"Speaker 1\", \"当然可以！比如，一个顶级的AI模型在经过大量训练后掌握了各种编程技巧，它可以轻松解决各种复杂的编程问题。而一个初级的AI模型如果通过知识蒸馏，可以学习到这些高级模型的所有编程技巧，无论是在高效的算法设计还是在复杂的代码编写上，都可以做到游刃有余。\"),\n",
      "    (\"Speaker 2\", \"这真是太棒了！比如说，当一个高级的自动驾驶系统通过一系列的任务和问题教会了一个初级系统如何在各种复杂的情况下安全驾驶，就像是给一个初级的LLaMa模型提供了一套完整的驾驶指南。\"),\n",
      "    (\"Speaker 1\", \"正是如此！这样的过程不仅仅让初级系统学会了如何驾驶，还让它了解了整个驾驶过程背后的逻辑和规则，从而在未来遇到复杂情况时也能应对自如。\"),\n",
      "    (\"Speaker 2\", \"太神奇了！那这种知识蒸馏过程，对AI来说是不是就像是一本魔法宝典，既是指导手册又是工具书？\"),\n",
      "    (\"Speaker 1\", \"对极了！就像一本魔法宝典不仅包含了所有魔法的步骤和技巧，还包含了如何在不同情境下使用这些魔法的知识。知识蒸馏就是这样的宝典，帮助初级系统提升到高级系统的能力。\"),\n",
      "    (\"Speaker 2\", \"听起来真是太妙了！你能不能举个现实世界中的例子，比如一个高级的医疗诊断系统通过知识蒸馏帮助一个初级的系统提高诊断能力？\"),\n",
      "    (\"Speaker 1\", \"换一个角度来看，就像一个高级的医疗诊断系统通过一系列的任务和问题教会了初级系统如何识别和诊断各种疾病。这样，初级系统可以通过模仿高级系统的学习路径，提高自身在医疗领域的诊断能力，从而更准确地诊断病情。\"),\n",
      "    (\"Speaker 2\", \"太赞了！这样初学者系统可以在未来像高级系统那样精准地进行诊断。\"),\n",
      "    (\"Speaker 1\", \"没错！知识蒸馏就像是给初学者系统提供了一套完整的指南和训练，让它们不仅能完成简单任务，还能应对各种复杂情况，真正做到像高级系统一样出色。\"),\n",
      "    (\"Speaker 2\", \"这真是太令人振奋了！我已经迫不及待想要了解更多关于知识蒸馏的秘密了。\"),\n",
      "    (\"Speaker 1\", \"哈哈，我也同样迫不及待。我们下次节目再见，希望大家继续关注我们的播客，探索更多科技的奇妙之处。\"),\n",
      "]\n",
      "==========\n",
      "Prompt: 1965 tokens, 236.069 tokens-per-sec\n",
      "Generation: 1235 tokens, 31.141 tokens-per-sec\n",
      "Peak memory: 4.388 GB\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "现在我们看看输出的效果",
   "id": "612a27e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:37:22.961731Z",
     "start_time": "2024-10-31T16:37:22.959357Z"
    }
   },
   "cell_type": "code",
   "source": "outputs",
   "id": "5de0be7cf7d9575d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n    (\"Speaker 1\", \"欢迎收听我们的播客，让我们深入探讨一个充满魔法和奇迹的话题：知识蒸馏。我是你们的引导者，今天我们将讨论如何让开源的大规模语言模型如LLaMa和Mistral变得更强壮、更聪明。我们将会用一些有趣的比喻和生动的例子来解释这一复杂的主题。\"),\\n    (\"Speaker 2\", \"哦，听起来好神奇啊！什么是知识蒸馏呢？\"),\\n    (\"Speaker 1\", \"哈哈，你很兴奋嘛！知识蒸馏就像是给一个初学者魔术师提供了一份详细的表演指南。具体来说，就是如何将一个高级模型的知识和技巧倾囊相授，让一个低级模型也能像高级模型一样出色。想象一下，如果一个顶级魔术大师(Jo RooGan模型)把他的所有技巧传授给一个初学者(JaLaMa模型)，这个初学者能否学会用最专业的方式表演魔术。\"),\\n    (\"Speaker 2\", \"嗯，这听起来就像是在给初学者一个详细的指南，而不是直接告诉他怎么做。那高级模型的技巧如何被传授给初学者呢？\"),\\n    (\"Speaker 1\", \"没错，这就像是老师在旁边一步步示范教学。高级模型会通过一系列的任务和问题来训练初学者。就像一个高级魔术师在表演过程中，会不断展示各种技巧和手法，让初学者学习如何通过一系列的动作完成复杂的表演。\"),\\n    (\"Speaker 2\", \"哈哈，就像是在看魔术表演学习一样！那这种知识转移对初学者模型有什么具体帮助呢？\"),\\n    (\"Speaker 1\", \"很好，你已经触到了关键之处！通过这些一步步的学习，初学者模型可以说在理解能力和应对复杂任务的能力上都有了显著提升。就像是初学者慢慢从只能做简单的魔术，到能够表演最复杂的魔术一样。\"),\\n    (\"Speaker 2\", \"那如果我做一个类比，高级魔术师的表演就像是知识蒸馏的过程，而初学者的训练就像是提高了数据增强吗？\"),\\n    (\"Speaker 1\", \"哈哈，你又洞察到了关键点。数据增强不仅仅是添加更多的训练数据，而更多是通过知识蒸馏，让模型理解和掌握更深层次的知识。就像一个高级魔术师通过不断的实践，学习各种技巧，然后通过这些技巧来完成最复杂的表演。\"),\\n    (\"Speaker 2\", \"那么，知识蒸馏的过程对于实现实体例的突变，是不是就像是高级魔术师使用魔法道具一样强大？\"),\\n    (\"Speaker 1\", \"简直就是！知识蒸馏就像高级魔术师使用魔法道具，它不仅让模型学会如何完成任务，还能让模型理解背后的逻辑，从而在各种复杂的情况下做出最佳决策。这就像是模型学会了如何在没有魔法道具的情况下使用最真实的技巧完成任务。\"),\\n    (\"Speaker 2\", \"这真是太神奇了！那这种知识蒸馏的过程对于一个开源的模型来说，是不是就像吃了一颗让它们瞬间领悟所有魔法技巧的 Fantastic Feed（假设这是一种特殊的训练方法）呢？\"),\\n    (\"Speaker 1\", \"完美比喻！就像一个普通的模型通过这样的特殊训练方法，瞬间掌握了高级模型的所有技巧，知识蒸馏的过程就是让原本不了解这些技巧的模型，现在可以轻松应对各种复杂的任务。这样，它们能够像一个高级模型一样出色地完成各种任务。\"),\\n    (\"Speaker 2\", \"[叹气]这太令人激动了！你能不能再举个真实世界中的例子，让我们更好地理解这个过程？\"),\\n    (\"Speaker 1\", \"当然可以！比如，一个顶级的AI模型在经过大量训练后掌握了各种编程技巧，它可以轻松解决各种复杂的编程问题。而一个初级的AI模型如果通过知识蒸馏，可以学习到这些高级模型的所有编程技巧，无论是在高效的算法设计还是在复杂的代码编写上，都可以做到游刃有余。\"),\\n    (\"Speaker 2\", \"这真是太棒了！比如说，当一个高级的自动驾驶系统通过一系列的任务和问题教会了一个初级系统如何在各种复杂的情况下安全驾驶，就像是给一个初级的LLaMa模型提供了一套完整的驾驶指南。\"),\\n    (\"Speaker 1\", \"正是如此！这样的过程不仅仅让初级系统学会了如何驾驶，还让它了解了整个驾驶过程背后的逻辑和规则，从而在未来遇到复杂情况时也能应对自如。\"),\\n    (\"Speaker 2\", \"太神奇了！那这种知识蒸馏过程，对AI来说是不是就像是一本魔法宝典，既是指导手册又是工具书？\"),\\n    (\"Speaker 1\", \"对极了！就像一本魔法宝典不仅包含了所有魔法的步骤和技巧，还包含了如何在不同情境下使用这些魔法的知识。知识蒸馏就是这样的宝典，帮助初级系统提升到高级系统的能力。\"),\\n    (\"Speaker 2\", \"听起来真是太妙了！你能不能举个现实世界中的例子，比如一个高级的医疗诊断系统通过知识蒸馏帮助一个初级的系统提高诊断能力？\"),\\n    (\"Speaker 1\", \"换一个角度来看，就像一个高级的医疗诊断系统通过一系列的任务和问题教会了初级系统如何识别和诊断各种疾病。这样，初级系统可以通过模仿高级系统的学习路径，提高自身在医疗领域的诊断能力，从而更准确地诊断病情。\"),\\n    (\"Speaker 2\", \"太赞了！这样初学者系统可以在未来像高级系统那样精准地进行诊断。\"),\\n    (\"Speaker 1\", \"没错！知识蒸馏就像是给初学者系统提供了一套完整的指南和训练，让它们不仅能完成简单任务，还能应对各种复杂情况，真正做到像高级系统一样出色。\"),\\n    (\"Speaker 2\", \"这真是太令人振奋了！我已经迫不及待想要了解更多关于知识蒸馏的秘密了。\"),\\n    (\"Speaker 1\", \"哈哈，我也同样迫不及待。我们下次节目再见，希望大家继续关注我们的播客，探索更多科技的奇妙之处。\"),\\n]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "d495a957",
   "metadata": {},
   "source": "让我们将处理好的内容保存到pickle文件中，以便在Notebook 4中使用"
  },
  {
   "cell_type": "code",
   "id": "281d3db7-5bfa-4143-9d4f-db87f22870c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:37:23.047398Z",
     "start_time": "2024-10-31T16:37:23.044780Z"
    }
   },
   "source": [
    "with open('./resources/podcast_ready_data.pkl', 'wb') as file:\n",
    "    pickle.dump(outputs, file)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "2dccf336",
   "metadata": {},
   "source": [
    "### 最后一个 Notebook: 讲稿转音频\n",
    "\n",
    "现在我们的讲稿已完全准备好了，接下来我们将在下一个 Notebook 中生成播客音频。"
   ]
  },
  {
   "cell_type": "code",
   "id": "21c7e456-497b-4080-8b52-6f399f9f8d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T16:37:23.069100Z",
     "start_time": "2024-10-31T16:37:23.067108Z"
    }
   },
   "source": [
    "#fin"
   ],
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
